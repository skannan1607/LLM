# -*- coding: utf-8 -*-
"""LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lA8MiTtn_-3slshRsaxQ8QJnFNThfX2l
"""

from transformers import pipeline
classifier = pipeline("text-classification")
result = classifier("I am good ")
print(result)

from transformers import pipeline
classifier = pipeline("text-classification",model="mrm8488/bert-tiny-finetuned-sms-spam-detection")
msg = ["Congrats ! You won a free iphone.Click here to claim." , "You won a prize"]

# predict spam or ham --> need to be fine tuned

for m in msg:
    result = classifier(m)
    print(f"MESSAGE:{m}")
    print(f"Prediction: {result[0]['label']}, Score: {result[0]['score']:.4f}")

qa_pipeline = pipeline("question-answering")
context = "Python was created by Guiddo von rossum in 1991"
question = ["When was created??","by whom"]
for q in question:
  result = qa_pipeline(context=context,question=q)
  print(f"Question: {q}")
  print(f"Answer: {result['answer']} (score: {result['score']:.4f})")

generator = pipeline("text-generation",model='gpt2')
print(generator("Hello, I'm a language model,",max_length=30,num_return_sequences=5))

summarizer = pipeline("summarization",model="facebook/bart-large-cnn")
text = "Artificial intelligence is transforming industries and it is a boon"
print(summarizer(text,max_length=50,min_length=1,do_sample=False))

classifier = pipeline("zero-shot-classification",model="facebook/bart-large-mnli")
sequence = "I love writing code in python and building large language models."
labels = ['travel', 'cooking', 'dancing','education','technology']
result = classifier(sequence, candidate_labels=labels)
print(result)

from transformers import pipeline

translator = pipeline("translation", model="facebook/mbart-large-50-many-to-many-mmt")
text = "Artificial intelligence is transforming the world"
translation = translator(text, src_lang="en_XX", tgt_lang="de_DE")
print("Original:", text)
print("French Translation:", translation[0]['translation_text'])

from transformers import pipeline

generator = pipeline("text-generation", model="gpt2")

prompt = """
1. "Hello all" = "bonjor"
2. "How are you?" = "commet"
"""

result = generator(prompt, max_length=100, do_sample=True, top_k=50)
print(result[0]['generated_text'])