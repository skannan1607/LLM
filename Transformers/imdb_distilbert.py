# -*- coding: utf-8 -*-
"""IMDB DISTILBERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17ZazuB-4avHgDHvcMpxM-pRw7uk7IBEz
"""

# --- DistilBERT Model for IMDB Sentiment Analysis ---

from transformers import DistilBertTokenizer, DistilBertForSequenceClassification
from transformers import Trainer, TrainingArguments
from datasets import load_dataset
import os

# Disable W&B logging
os.environ["WANDB_DISABLED"] = "true"

# Load IMDB dataset
dataset = load_dataset("imdb")

# Model name
model_name = "distilbert-base-uncased"

# Load tokenizer and model
tokenizer = DistilBertTokenizer.from_pretrained(model_name)
model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)

# Tokenize data
def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

tokenized_datasets = dataset.map(tokenize_function, batched=True)
train_dataset = tokenized_datasets["train"]
test_dataset = tokenized_datasets["test"]

# Training arguments (no evaluation_strategy)
training_args = TrainingArguments(
    output_dir="./distilbert_results",
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=2,
    weight_decay=0.01,
)

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    tokenizer=tokenizer,
)

# Train and evaluate
trainer.train()
trainer.evaluate()

from transformers import AutoModelForSequenceClassification, AutoTokenizer

model.save_pretrained("./distilbert_results")
tokenizer.save_pretrained("./distilbert_results")

from transformers import pipeline

# Load your trained model
sentiment_pipeline = pipeline(
    "sentiment-analysis",
    model="./distilbert_results",     # path to your fine-tuned model
    tokenizer="distilbert-base-uncased"
)

# Test sentences
texts = [
    "I absolutely loved this movie! The acting was brilliant.",
    "This film was terrible and a complete waste of time.",
    "It was okay, not great but not bad either.",
    "The storyline was engaging and the visuals were stunning!",
    "The plot was confusing and the ending made no sense."
]

# Run predictions
results = sentiment_pipeline(texts)

# Display
for text, result in zip(texts, results):
    print(f"Text: {text}\n   --> Label: {result['label']} | --> Confidence: {result['score']:.4f}\n")